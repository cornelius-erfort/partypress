---
title: "Preparing the textual data"
author: "Cornelius Erfort"
date: "9 Aug 2021"
output: 
  pdf_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, tidy.opts=list(width.cutoff = 80), tidy = T, python.reticulate = F)
knitr::opts_knit$set(root.dir = dirname(getwd()))

```


# Setting up

This script requires the files which are not included on GitHub.

## Loading packages

This script is based mainly on the functions of the quanteda package. For the cross-validation of the textmodels, quanteda.classifiers has to be loaded from GitHub.

```{r packages, message=FALSE, warning=FALSE, include=FALSE, results='hide'}
start_time <- Sys.time()

packages <- c(
  "quanteda", "quanteda.textplots", "quanteda.textmodels", "quanteda.textstats", "quanteda.classifiers", "dplyr", "tm", "rmarkdown", "plyr", "readr", "ggplot2", "stringr", "formatR", "readstata13", "lubridate", "glmnet", "kableExtra", "stargazer", "tidyr", "extrafont", "openxlsx", "tools", "caret", "Seurat")

lapply(packages[!(packages %in% rownames(installed.packages()))], install.packages)

invisible(lapply(packages, require, character.only = T))

theme_update(text = element_text(family = "LM Roman 10")) # Set font family for ggplot

# loadfonts()
# loadfonts(device = "pdf")
source("scripts/functions.R")

seed <- 1621447882
set.seed(seed)

if(!dir.exists("files")) dir.create("files")

```

## Load the unlabeled data

```{r unlabeled, out.width = "80%"}
list.files("data/all")


if(file.exists("data/unlabeled.RData")) load("data/unlabeled.RData") else {
  unlabeled <- data.frame()

  for (country in list.files("data/all", full.names = T)) {
    print(country)
    load(country)
    unlabeled <- get(basename(country) %>% str_remove("\\.[:alpha:]*")) %>% 
      filter(!is.na(date)) %>% mutate(date = str_replace_all(date, "_", "-")) %>%
      select(c(country, id, party, year, date, filepath, header, text)) %>%
      rbind.fill(unlabeled)
  }
  
  
  # Remove press releases without date
  unlabeled$date <- ymd(unlabeled$date)
  unlabeled <- filter(unlabeled, !is.na(date))

  save(unlabeled, file = "data/unlabeled.RData")
}


table(unlabeled$country)

```



## Load the labeled data

```{r data, out.width = "80%"}
# Read the labeled data into one dataframe

if(file.exists("data/labeled.RData")) load("data/labeled.RData") else {
  labeled <- data.frame()

  for (country in list.files("data/labeled", full.names = T) %>% str_subset("(xlsx)|(csv)") %>% str_subset("labeled\\/[:alpha:]") ) {
    
    if(file_ext(country) == "xlsx") {
      print("xlsx")
      print(country)
      labeled_c <- read.xlsx(country) 
      if(names(labeled_c) %>% str_detect("Spalte") %>% any()) labeled_c <- select(labeled_c, -c(starts_with("Spalte"))) 
        # Add var for cross validation
        labeled_c$cv_sample <- createFolds(1:nrow(labeled_c), k = 5, list = F)
      labeled <- labeled_c %>% 
        mutate(country = basename(country) %>% str_remove("-.*")) %>% 
        rbind.fill(labeled)
      print(nrow(labeled))
    } else {
      print("csv")
      print(country)
      labeled_c <- read.csv(country,
                          encoding = ifelse(str_detect(country, "spain"), "latin1", "unknown"),
                          sep = ",")
      if(names(labeled_c) %>% str_detect("Spalte") %>% any()) labeled_c <- labeled_c %>% select(-c(starts_with("Spalte")))
        # Add var for cross validation
        labeled_c$cv_sample <- createFolds(1:nrow(labeled_c), k = 5, list = F)
      labeled <- labeled_c  %>% 
        mutate(country = basename(country) %>% str_remove("-.*")) %>% 
        rbind.fill(labeled)
      print(nrow(labeled))
    } 
  }
  
  # Tidy date and remove press releases without date
  labeled$date[substr(labeled$date, 5, 5) == "-"] <- labeled$date[substr(labeled$date,   5, 5) == "-"] %>% ymd()
  labeled$date[substr(labeled$date, 3, 3) %in% c("-", "/")] <-   labeled$date[substr(labeled$date, 3, 3) %in% c("-", "/")] %>% dmy()
  labeled$date <- labeled$date %>% as.numeric() %>% as.Date(origin = "1970-01-01")
  labeled <- filter(labeled, !is.na(date))
  

  
  # Tidy issue
  labeled$issue <- str_replace_all(labeled$issue, c("19a" = "191", "19A" = "191", "19b" =  "192", "2 or 192" = "2", "98 or 191" = "98", "201" = "20", "145" = "14", "19$" = "191"))
  labeled$issue <- ifelse(labeled$issue %in% c("0", "."), NA, labeled$issue)

  table(labeled$issue, useNA = "always")
  labeled <- filter(labeled, !is.na(issue) & issue != ".")
  
  labeled$issue %>% unique
  
  labeled$issue_cross <- str_replace_all(labeled$issue_cross, c("19a" = "191", "19A" = "191", "19b" =  "192", "2 or 192" = "2", "98 or 191" = "98", "201" = "20", "145" = "14", "19$" = "191", "98 or 191" = "98"))
  labeled$issue_cross[labeled$issue_cross == "."] <- NA
  labeled$issue_cross %>% unique

    # Tidy position

  labeled$position %>% table
  labeled$position <- str_replace_all(labeled$position, c("1;1" = "1", "11" = "1", "22" = "2", "24" = "2")) %>% as.numeric()
  labeled$position_cross %>% table
  labeled$position_cross <- str_replace_all(labeled$position_cross, c("1;1" = "1", "11" = "1", "22" = "2", "24" = "2")) %>% as.numeric()

  labeled <- labeled %>% select("country", "header", "text", "issue", "issue_cross", "position", "position_cross", "party", "date", "cv_sample", "id")
  
  

  
  table(labeled$country, labeled$cv_sample)
  
  # Sort documents
  labeled <- labeled[order(labeled$country, labeled$id), ]
  
  # save(labeled, file = "data/labeled.RData")
}

labeled$country  %>% table

table(labeled$country, useNA = "always")


```


# Add labels to unlabeled data to create the main dataset
```{r}
unlabeled$id <- as.numeric(unlabeled$id)
labeled$id <- as.numeric(labeled$id)

press <- merge(unlabeled, labeled %>% select(country, id, issue, position, issue_cross, position_cross, cv_sample), by = c("country", "id"), all.x = T)
press$cv_sample[is.na(press$cv_sample)] <- -1
```

# Add parlgov labels

```{r}

# press$party %>% unique

parties <- read.xlsx("data/parties-import.xlsx")

(press$party %>% unique) %in% parties$X6

press <- merge(press, parties, by.x = c("country", "party"), by.y = c("country_name", "X6"), all.x = T)

press$parlgov_id %>% unique %>% sort %>% length 
# 67 different parlgov_ids

press <- merge(press, data.frame(issue = unique(press$issue) %>% sort, label = (1:length(unique(press$issue) %>% sort) - 1)), by = "issue", all.x = T)

press$label[is.na(press$label)] <- -1

save(press, file = "files/press.RData")
write.csv(press, file = "files/press.csv")

```


# Superlearner: Export csv files for models in Colab

``` {r superlearner}
presscorpus <- corpus(str_c(press$header, " ", press$text),
                       docvars = select(press, c(country, id, issue, party_name, cv_sample)))

for (country in press$country %>% unique) {
  print(country)
  
  countrycorpus <-  presscorpus[presscorpus$country == country & presscorpus$cv_sample != -1, ]
  ndoc(countrycorpus) %>% print
  
  # Stopwords
  if(country == "poland") countrystop <-  stopwords::stopwords("pl", source = "stopwords-iso") else countrystop <- stopwords(str_replace_all(country, c("germany" = "de", "austria" = "de", "spain" = "es", "netherlands" = "nl", "ireland" = "en", "uk" = "en", "sweden" = "sw", "denmark" = "da")))
  countrystop
  
  
  if(!file.exists(str_c("files/dfmat-", country, ".csv"))) {
    # Create dfm
  dfmat <- countrycorpus %>%
    dfm(remove = countrystop, # Stem and remove stopwords, punctuation etc.
        stem = T, remove_punct = T, remove_number = T, remove_symbols = T, remove_url = T) %>% 
    dfm_trim(min_docfreq = 0.005, max_docfreq = .9, # Remove words occurring <.5% or > 80% of docs
             docfreq_ = "prop") %>%
    suppressWarnings()
  
  # Save
  cbind(cv_sample = dfmat$cv_sample, label = dfmat$issue, as.data.frame(dfmat))[, -c(3)] %>% write.csv(str_c("files/dfmat-", country, ".csv"), row.names = F)
  }
  
    if(!file.exists(str_c("files/dfmat_alt-", country, ".csv"))) {
      # Create alternative dfm (bigrams and tfidf)
  dfmat_alt <- countrycorpus %>%
    tokens() %>% tokens_ngrams(n = 1:2) %>%
    dfm(remove = countrystop, # Stem and remove stopwords, punctuation etc.
        stem = T, remove_punct = T, remove_number = T, remove_symbols = T, remove_url = T) %>% 
    dfm_trim(max_docfreq = .06, # Remove words occurring >6% of docs
             docfreq_ = "prop") %>%
    dfm_trim(min_docfreq = 5, # Remove words occurring in <5 docs
             docfreq_ = "count") %>% suppressWarnings()
  
  # Save
  cbind(cv_sample = dfmat_alt$cv_sample, label = dfmat_alt$issue, as.data.frame(dfmat_alt))[, -c(3)] %>% write.csv(str_c("files/dfmat_alt-", country, ".csv"), row.names = F)
    }
  

}

```






```{r script_eval}
# Time needed to run script
print(Sys.time() - start_time) 
```










