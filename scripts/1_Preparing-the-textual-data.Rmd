---
title: "Preparing the textual data"
author: "Cornelius Erfort"
date: "9 Aug 2021"
output: 
  pdf_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, tidy.opts=list(width.cutoff = 80), tidy = T, python.reticulate = F)
knitr::opts_knit$set(root.dir = dirname(getwd()))

```

# Setting up

This script requires the files which are not included on GitHub.

## Loading packages

This script is based mainly on the functions of the quanteda package. For the cross-validation of the textmodels, quanteda.classifiers has to be loaded from GitHub.

```{r packages, message=FALSE, warning=FALSE, results='hide'}
start_time <- Sys.time()

packages <- c(
  "quanteda", "dplyr", "tm", "rmarkdown", "plyr", "readr", "ggplot2", "stringr", "formatR", "readstata13", "lubridate", "kableExtra", "stargazer", "xlsx")

lapply(packages[!(packages %in% rownames(installed.packages()))], install.packages)
invisible(lapply(packages, require, character.only = T))

theme_update(text = element_text(family = "LM Roman 10")) # Set font family for ggplot

set.seed(4325)
```

## Loading data

For the evaluation of classifiers, we use the data for Germany.

The data for Germany consists of 2,612 labeled press releases. The dataset is not uploaded on GitHub.

```{r data, out.width = "80%"}
labeled <- read.xlsx("data/labeled/germany-labeled.xlsx", sheetIndex = 1) %>%
  suppressWarnings()
nrow(labeled)

# Clean
labeled <- labeled %>% mutate(issue = issue %>% as.numeric())

table(labeled$issue, useNA = "always")

# Subset to relevant vars
textpress <- labeled %>% select("header", "text", "issue", "position", "id", "party", "date")
rm(labeled)

# Distribution of issues in the hand-coded sample
table(textpress$issue) %>% as.data.frame() %>% dplyr::rename(issue = Var1, n = Freq) %>% t() %>% kbl(booktabs = T) %>% 
  kable_styling(latex_options = "scale_down")

```

## Merge categories

In order to improve the classification, similar topics are merged or subsumed under the "Other" category. In practice, press releases regarding, for instance, Environment and Energy are often not distinguishable. Furthermore, small categories with very few observations are not suitable for automated classification.

```{r categories}
textpress$issue_r1 <- as.numeric(textpress$issue)

# Merge categories
textpress <- textpress %>% mutate(issue_r1 = recode(issue_r1,
                           `8`  = 7,  # Environment & Energy
                           `13` = 10, # Transportation & Welfare
                           `14` = 10, # Housing & Welfare
                           `18` = 15, # Foreign Trade and Domestic Commerce
                           `98` = 99, # Non-thematic and Other
                           `23` = 99) # Culture: Too few observations
                                                  )
# Category descriptions
issue_categories <- 
  data.frame(issue_r1 = c(1:7, 9:10, 12, 15:17, 20, 99, 191:192), 
             issue_r1_descr = c("Macroeconomics", "Civil Rights", 
                                "Health", "Agriculture", "Labor", "Education", "Environment and Energy", 
                                "Immigration", "Welfare", "Law and Crime", "Commerce", "Defense", 
                                "Technology", "Government Operations", "Other", "International Affairs", "EU"))
issue_categories %>% dplyr::rename("Issue number" = issue_r1, "Issue name" = issue_r1_descr) %>% 
  kbl(booktabs = T)

# Write latex table
if(!dir.exists("tables")) dir.create("tables")
latex_out <- issue_categories[c(1:13, 16:17, 14:15), ] %>% 
  mutate(issue_r1 = as.character(issue_r1) %>% str_replace_all(c("191" = "19.1", "192" = "19.2"))) %>%
  dplyr::rename(Code = issue_r1, Topic = issue_r1_descr) %>%
  stargazer(out = "tables/issue-categories.tex", summary = F, rownames = F, 
            title = "Issue categories used for classification", 
            label = "tab:issue-categories") %>% 
  capture.output()

# Distribution with merged categories
table(textpress$issue_r1) %>% as.data.frame() %>% 
  dplyr::rename(issue = Var1, n = Freq) %>% t() %>% kbl(booktabs = T) %>% 
  kable_styling(latex_options="scale_down")

# Party names
party_names <- data.frame(party = c("90gruene_fraktion", 
                                    "afd_bundesverband", "afd_fraktion",
                                    "fdp_bundesverband", "fdp_fraktion",
                                    "linke_fraktion", "spd_fraktion",
                                    "union_fraktion"), 
                          party_name = c("Bündnis 90/Die Grünen - Fraktion", 
                                         "AfD - Bundesverband", "AfD - Fraktion", 
                                         "FDP - Bundesverband", "FDP - Fraktion", 
                                         "DIE LINKE - Fraktion", "SPD - Fraktion", 
                                         "CDU/CSU - Fraktion"))
textpress <- merge(textpress, party_names, by = "party")

# Distribution by parties
table(textpress$party_name) %>% as.data.frame() %>% 
  dplyr::rename(party = Var1, n = Freq) %>% kbl(booktabs = T)

table(textpress$party_name, substr(textpress$date, 1, 4)) %>% 
  as.data.frame.matrix() %>% kbl(booktabs = T)

# Combine header and text
textpress$htext <- str_c(textpress$header, " ", textpress$text)

# Make order of documents random
textpress <- textpress[sample(1:nrow(textpress), nrow(textpress)), ]
textpress$cv_sample <- sample(1:5, nrow(textpress), replace = T)

# Save dataframe (do not overwrite because the cross-validation folds are saved here)
if(!file.exists("supervised-files/data/textpress.RData")) save(textpress, file = "supervised-files/data/textpress.RData") else{
  load("supervised-files/data/textpress.RData")
}
```


# Supervised models
## Creating the document frequency matrix (dfm)

We create a text corpus based on the header and text of each press release. We draw a random sample from the corpus to create a training and a test dataset. The test dataset consists of approx. one fifth of the documents.

Subsequently, we follow standard procedures for the preparation of the document frequency matrix. First, we remove stopwords and stem the words in order to better capture the similarities across documents. Second, we remove all punctuation, numbers, symbols and URLs. In a last step, we remove all words occurring in less than 0.5% or more than 90% of documents.


```{r dfm}
if(!dir.exists("supervised-files")) dir.create("supervised-files")

if(file.exists("supervised-files/data/dfmat.RData")) load("supervised-files/data/dfmat.RData") else {
    
corp_press <- corpus(str_c(textpress$header, " ", textpress$text),
                       docvars = select(textpress, c(id, issue, issue_r1, party_name, cv_sample)))

# Create dfm
dfmat <- corpus_subset(corp_press) %>%
  dfm(remove = stopwords("de"), # Stem and remove stopwords, punctuation etc.
      stem = T, remove_punct = T, remove_number = T, remove_symbols = T, remove_url = T) %>% 
  dfm_trim(min_docfreq = 0.005, max_docfreq = .9, # Remove words occurring <.5% or > 80% of docs
           docfreq_ = "prop") %>%
  suppressWarnings()
save(dfmat, file = "supervised-files/data/dfmat.RData")



# Create alternative dfm (bigrams and tfidf)
dfmat_alt <- corpus_subset(corp_press) %>%
  tokens() %>% tokens_ngrams(n = 1:2) %>%
  dfm(remove = stopwords("de"), # Stem and remove stopwords, punctuation etc.
      stem = T, remove_punct = T, remove_number = T, remove_symbols = T, remove_url = T) %>% 
  dfm_trim(max_docfreq = .06, # Remove words occurring >6% of docs
           docfreq_ = "prop") %>%
   dfm_trim(min_docfreq = 5, # Remove words occurring in <5 docs
           docfreq_ = "count") %>% suppressWarnings()

save(dfmat_alt, file = "supervised-files/data/dfmat_alt.RData")

}

```

# Superlearner
``` {r superlearner}
if(!dir.exists("superlearner-files")) dir.create("superlearner-files")

## Create training and test set (also as csv for Python)
cbind(cv_sample = dfmat$cv_sample, label = dfmat$issue_r1, as.data.frame(dfmat)) %>% select(-c(doc_id)) %>% write.csv("supervised-files/data/dfmat.csv", row.names = F)

## Create training and test set (also as csv for Python)
cbind(cv_sample = dfmat_alt$cv_sample, label = dfmat_alt$issue_r1, as.data.frame(dfmat_alt)) %>% select(-c(doc_id)) %>% write.csv("supervised-files/data/dfmat_alt.csv", row.names = F)

```

# Readme, semi-supervised, and transfer models

Genereate csv file with unlabeled and labeled documents.

```{r semi-transfer}
if(!dir.exists("semi-files")) dir.create("semi-files")
if(!dir.exists("transfer-files")) dir.create("transfer-files")
if(!dir.exists("readme-files")) dir.create("readme-files")


# Load all press releases
load("data/all/germany.RData")
alldocs <- germany %>% select(country, party, date, header, text, id)
nrow(alldocs) # 44,950
names(alldocs)

# Add labels and folds by id from textpress
load("supervised-files/data/textpress.RData")
alldocs <- merge(alldocs, select(textpress, c(id, issue, issue_r1, cv_sample)), by = "id", all = T)
nrow(alldocs) # 44,950

alldocs$cv_sample[is.na(alldocs$cv_sample)] <- -1


# alldocs[!(alldocs$id %in% germany$id), ] %>% View

# Combine header and text
alldocs$htext <- str_c(alldocs$header, " ", alldocs$text)
alldocs <- select(alldocs, -c(header, text))

alldocs$issue_r1[is.na(alldocs$issue_r1)] <- -1

# Show distribution of text length (labeled data)
sapply(alldocs$htext[alldocs$issue_r1 != -1], str_length) %>% density() %>% plot

# Count words/tokens
sapply(alldocs$htext, function(x) lengths(gregexpr("\\W+", x)) + 1) %>% summary # max_seq_length = 512

# Make labels compatible with transformers (0-16 instead of CAP labels)
labels <- data.frame(issue_r1 = unique(alldocs$issue_r1) %>% sort, label = c(-1, 0:16))
alldocs <- merge(alldocs, labels, by = "issue_r1", all.x = T)


table(alldocs$issue, useNA = "ifany")


# Write to csv

if(!file.exists("transfer-files/alldocs.csv")) write_csv(alldocs, file = "transfer-files/alldocs.csv")

if(!file.exists("semi-files/alldocs.csv")) write_csv(select(alldocs, -c(label)), file = "semi-files/alldocs.csv")

if(!file.exists("readme-files/alldocs.RData")) select(alldocs, -c(label)) %>% save(., file = "readme-files/alldocs.RData")


```


```{r script_eval}
# Time needed to run script
print(Sys.time() - start_time) 
```