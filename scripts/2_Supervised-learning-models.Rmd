---
title: "Supervised learning models"
author: "Cornelius Erfort"
date: "9 Aug 2021"
output: 
  pdf_document:
    dev: cairo_pdf
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, tidy.opts=list(width.cutoff = 80), tidy = T, python.reticulate = F)
knitr::opts_knit$set(root.dir = dirname(getwd()))
```

# Summary

In this script, we test the performance of a series of classifiers across a diverse set of parameter configurations and for two different dfm representations. 
For most classifiers, the tfidf-transformed dfm with bigrams (min_docfreq = 5 count, max_docfreq = .06 prop) yields a better performance.

The best accuracy of ?% is obtained using the Superlearner ensemble of classifiers (although this is not cross-validated). Ridge (L2) is the best single classifier with 66.9%.

The fastest classifier is Naive bayes, estimated locally in 0.24 seconds (accuracy 65.98 %).


# Setting up

This script requires the files which are not included on GitHub.

## Loading packages

This script is based mainly on the functions of the quanteda package. For the cross-validation of the textmodels, quanteda.classifiers has to be loaded from GitHub.

```{r packages, message=FALSE, warning=FALSE, results='hide'}
start_time <- Sys.time()

packages <- c(
  "quanteda", "quanteda.textmodels", "dplyr", "caret", "randomForest", "tm", "rmarkdown", "plyr", "readr", "ggplot2", "stringr", "formatR", "readstata13", "lubridate", "reticulate", "doMC", "glmnet", "kableExtra", "stargazer", "extrafont", "remotes", "devtools", "tidyr")

# lapply(packages[!(packages %in% rownames(installed.packages()))], install.packages) # Windows doesn't like this...


if(!("quanteda.classifiers" %in% rownames(installed.packages()))) {
  remotes::install_github("quanteda/quanteda.classifiers")
  # devtools::install_github("quanteda/quanteda.classifiers") 
} 

invisible(lapply(c(packages, "quanteda.classifiers"), require, character.only = T))
loadfonts(device = "pdf")
theme_update(text = element_text(family = "LM Roman 10")) # Set font family for ggplot

source("scripts/functions.R")

# Seed
seed <- 1621447882
set.seed(seed)

# Five-fold cross-validation (except Elastic Net and Random Forest)
folds_cv <- 5 

load("files/press.RData")
```


```{r supervised}

presscorpus <- corpus(str_c(press$header, " ", press$text),
                       docvars = select(press, c(country, id, issue, party_name, cv_sample)))

if(!file.exists("files/tm_eval.RData")) load("files/tm_eval.RData") else tm_eval <- data.frame()

# tm_eval <- filter(tm_eval, country != "poland")

for (country in  "poland") { # press$country %>% unique) { #
  print(country)
  
  countrycorpus <-  presscorpus[presscorpus$country == country & presscorpus$cv_sample != -1, ]
  ndoc(countrycorpus) %>% print
  
  # Stopwords
  if(country == "poland") countrystop <-  stopwords::stopwords("pl", source = "stopwords-iso") else countrystop <- stopwords(str_replace_all(country, c("germany" = "de", "austria" = "de", "spain" = "es", "netherlands" = "nl", "ireland" = "en", "uk" = "en", "sweden" = "sw", "denmark" = "da")))
  countrystop

  # Create dfm
  dfmat <- countrycorpus %>%
    dfm(remove = countrystop, # Stem and remove stopwords, punctuation etc.
        stem = T, remove_punct = T, remove_number = T, remove_symbols = T, remove_url = T) %>% 
    dfm_trim(min_docfreq = 0.005, max_docfreq = .9, # Remove words occurring <.5% or > 80% of docs
             docfreq_ = "prop") %>%
    suppressWarnings()
  
  # Create alternative dfm (bigrams and tfidf)
  dfmat_alt <- countrycorpus %>%
    tokens() %>% tokens_ngrams(n = 1:2) %>%
    dfm(remove = countrystop, # Stem and remove stopwords, punctuation etc.
        stem = T, remove_punct = T, remove_number = T, remove_symbols = T, remove_url = T) %>% 
    dfm_trim(max_docfreq = .06, # Remove words occurring >6% of docs
             docfreq_ = "prop") %>%
    dfm_trim(min_docfreq = 5, # Remove words occurring in <5 docs
             docfreq_ = "count") %>% suppressWarnings()
  
  ##############
  # 1 Naive bayes
  ##############
  model_name <- "Naive bayes"
  model_id <- 1
  print(model_name)
  print(model_id)
   if(!(str_c(country, model_id) %in% str_c(tm_eval$country, tm_eval$model_id))) tm_eval <- textmodel_evaluate(dfmat, dfmat$issue, k = folds_cv, seed = seed,
            model = "textmodel_nb", fun = c("accuracy", "precision", "recall", "f1_score"),
            parameters = list(prior = c("termfreq"), distribution = c("multinomial", "Bernoulli"), smooth = c(1, 2, 3)), by_class = T) %>% 
     dplyr::rename(weight = prior) %>% 
     mutate(model_name = model_name, country = country, model_id = model_id) %>% 
     rbind.fill(tm_eval)
  

  
  ## with alternative DFM
  model_id <- model_id + 1
  print(model_id)
  if(!(str_c(country, model_id) %in% str_c(tm_eval$country, tm_eval$model_id)))  tm_eval <-  textmodel_evaluate(dfmat_alt, dfmat_alt$issue, k = folds_cv, seed = seed,
            model = "textmodel_nb", fun = c("accuracy", "precision", "recall", "f1_score"),
            parameters = list(distribution = c("multinomial", "Bernoulli"), smooth = c(1, 2, 3)), by_class = T) %>% 
    dplyr::mutate(weight = "tfidf") %>% 
    mutate(model_name = model_name, country = country, model_id = model_id) %>% 
    rbind.fill(tm_eval)
  
  
  ##############
  # 2 Ridge regression (L2)
  ##############
  model_name <- "Ridge (L2)"
  model_id <- model_id + 1
  print(model_name)
  print(model_id)
   if(!(str_c(country, model_id) %in% str_c(tm_eval$country, tm_eval$model_id))) tm_eval <- textmodel_evaluate(dfmat, dfmat$issue, k = folds_cv, seed = seed, model = "textmodel_svm", fun = c("accuracy", "precision", "recall", "f1_score"), 
      parameters = list(weight = c("uniform", "docfreq", "termfreq"), type = c(0, 7)), by_class = T) %>% 
     mutate(model_name = model_name, country = country, model_id = model_id) %>% 
     rbind.fill(tm_eval)
  
  ## with alternative DFM
  model_id <- model_id + 1
  print(model_id)
  if(!(str_c(country, model_id) %in% str_c(tm_eval$country, tm_eval$model_id)))  tm_eval <-  textmodel_evaluate(dfmat_alt, dfmat_alt$issue, k = folds_cv, seed = seed, model = "textmodel_svm", fun = c("accuracy", "precision", "recall", "f1_score"), parameters = list(type = c(0, 7)), by_class = T) %>% 
    dplyr::mutate(weight = "tfidf") %>% 
    mutate(model_name = model_name, country = country, model_id = model_id) %>% 
    rbind.fill(tm_eval)
  
  
  ##############
  # 3 Lasso regression (L1)
  ##############
  model_name <- "Lasso (L1)"
  model_id <- model_id + 1
  print(model_name)
  print(model_id)
   if(!(str_c(country, model_id) %in% str_c(tm_eval$country, tm_eval$model_id))) tm_eval <- textmodel_evaluate(dfmat, dfmat$issue, k = folds_cv, seed = seed, model = "textmodel_svm", fun = c("accuracy", "precision", "recall", "f1_score"), parameters = list(weight = c("uniform", "docfreq", "termfreq"), type = 6), by_class = T) %>% 
     mutate(model_name = model_name, country = country, model_id = model_id) %>% 
     rbind.fill(tm_eval)
  
  ## with alternative DFM
  model_id <- model_id + 1
  print(model_id)
  if(!(str_c(country, model_id) %in% str_c(tm_eval$country, tm_eval$model_id)))  tm_eval <-  textmodel_evaluate(dfmat_alt, dfmat_alt$issue, k = folds_cv, seed = seed, model = "textmodel_svm", fun = c("accuracy", "precision", "recall", "f1_score"), parameters = list(type = 6), by_class = T) %>% 
    dplyr::mutate(weight = "tfidf") %>% 
    mutate(model_name = model_name, country = country, model_id = model_id) %>% 
    rbind.fill(tm_eval)
  
  ##############
  # 4 SVM
  ##############
  model_name <- "SVM"
  model_id <- model_id + 1
  print(model_name)
  print(model_id)
   if(!(str_c(country, model_id) %in% str_c(tm_eval$country, tm_eval$model_id))) tm_eval <- textmodel_evaluate(dfmat, dfmat$issue, k = folds_cv, seed = seed, model = "textmodel_svm", fun = c("accuracy", "precision", "recall", "f1_score"), parameters = list(weight = c("uniform", "docfreq", "termfreq"), type = 4), by_class = T) %>% 
     mutate(model_name = model_name, country = country, model_id = model_id) %>% 
     rbind.fill(tm_eval)
  
  ## with alternative DFM
  model_id <- model_id + 1
  print(model_id)
  if(!(str_c(country, model_id) %in% str_c(tm_eval$country, tm_eval$model_id)))  tm_eval <-   textmodel_evaluate(dfmat_alt, dfmat_alt$issue, k = folds_cv, seed = seed, model = "textmodel_svm", fun = c("accuracy", "precision", "recall", "f1_score"), parameters = list(type = 4), by_class = T) %>% 
    dplyr::mutate(weight = "tfidf") %>% 
    mutate(model_name = model_name, country = country, model_id = model_id) %>% 
    rbind.fill(tm_eval)
  
  
  ##############
  # 5 Elastic net
  ##############
  model_name <- "Elastic net"
  model_id <- model_id + 1
  print(model_name)
  print(model_id)
   if(!(str_c(country, model_id) %in% str_c(tm_eval$country, tm_eval$model_id))) {
     
     
     # Register multicore backend 
     registerDoMC(cores = 4) 
     
     eval_start <- Sys.time()
     elasticnet_mod <- glmnet(x = dfm_subset(dfmat, dfmat$cv_sample != 1), 
                              y = dfm_subset(dfmat, dfmat$cv_sample != 1)$issue, 
                              family = "multinomial", 
                              alpha = 0.5, 
                              type.measure = "class", standardize = T) 
     eval_end <- Sys.time()
     
     # Get lambda with best accuracy
     elasticnet_pred <- predict(elasticnet_mod, newx = as.matrix(dfm_subset(dfmat, dfmat$cv_sample == 1)), type = "class")
     acc_list <- apply(elasticnet_pred, MARGIN = 2, FUN = function (x)  accuracy(x, dfm_subset(dfmat, dfmat$cv_sample == 1)$issue))
     elasticnet_pred <- predict(elasticnet_mod, newx = as.matrix(dfm_subset(dfmat, dfmat$cv_sample == 1)), type = "class", s = elasticnet_mod$lambda[which(unlist(acc_list) == max(acc_list %>% unlist))][1])
     elastic_net_test <- dfm_subset(dfmat, dfmat$cv_sample == 1)

     
     model_eval <- data.frame(accuracy = accuracy(elasticnet_pred, elastic_net_test$issue), 
           time = as.numeric(eval_end - eval_start),
           seed = seed,
           weight = "uniform",
           model_name = model_name,
           model_id = model_id,
           alpha = .5,
           distribution = "multinomial",
           country = country)
     
     add_param <- cbind(quanteda.classifiers::precision(elasticnet_pred, elastic_net_test$issue) %>% as.data.frame(), 
                        quanteda.classifiers::recall(elasticnet_pred, elastic_net_test$issue) %>% as.data.frame(), 
                        quanteda.classifiers::f1_score(elasticnet_pred, elastic_net_test$issue)  %>% as.data.frame() %>% mutate(class = rownames(.)))  %>% mutate(country = country)
     
     tm_eval <- merge(model_eval, add_param, by = "country") %>% rbind.fill(tm_eval)
     
   }
       
     
     
      ## with alternative DFM
      model_id <- model_id + 1
      print(model_id)
      

      if(!(str_c(country, model_id) %in% str_c(tm_eval$country, tm_eval$model_id)))  {
        

        # Get lambda with best accuracy
        eval_start <- Sys.time()
        elasticnet_mod_alt <- glmnet(x = dfm_subset(dfmat_alt, dfmat_alt$cv_sample != 1), 
                                     y = dfm_subset(dfmat_alt, dfmat_alt$cv_sample != 1)$issue,
                                     family = "multinomial", 
                                     alpha = 0.5,
                                     type.measure = "class", standardize = T) 
        eval_end <- Sys.time()
        
        elasticnet_pred_alt <- predict(elasticnet_mod_alt, newx = as.matrix(dfm_subset(dfmat_alt, dfmat_alt$cv_sample == 1)), type = "class")
        acc_list <- apply(elasticnet_pred_alt, MARGIN = 2, FUN = function (x)  accuracy(x, dfm_subset(dfmat, dfmat$cv_sample == 1)$issue))

        elasticnet_pred_alt <- predict(elasticnet_mod_alt, newx = as.matrix(dfm_subset(dfmat_alt, dfmat_alt$cv_sample == 1)), type = "class", s = elasticnet_mod_alt$lambda[which(unlist(acc_list) == max(acc_list %>% unlist))][1])
        elastic_net_test_alt <- dfm_subset(dfmat_alt, dfmat_alt$cv_sample == 1)
        
        model_eval <- data.frame(accuracy = accuracy(elasticnet_pred_alt, elastic_net_test_alt$issue), 
               time = as.numeric(eval_end - eval_start),
               seed = seed,
               weight = "tfidf",
               model_name = model_name,
               model_id = model_id,
               alpha = .5,
               distribution = "multinomial",
              country = country)
        
        add_param <- cbind(quanteda.classifiers::precision(elasticnet_pred_alt, elastic_net_test_alt$issue) %>% as.data.frame(), 
                           quanteda.classifiers::recall(elasticnet_pred_alt, elastic_net_test_alt$issue) %>% as.data.frame(), 
                           quanteda.classifiers::f1_score(elasticnet_pred_alt, elastic_net_test_alt$issue)  %>% as.data.frame() %>% mutate(class = rownames(.)))  %>% mutate(country = country)
     
     tm_eval <- merge(model_eval, add_param, by = "country") %>% rbind.fill(tm_eval)
        
        
        
      }
     

save(tm_eval, file = "files/tm_eval.RData")
}

```



```{r script_eval}
# Time needed to run script (much shorter when textmodels are just loaded from file)
# The estimation time for the single textmodels can found in the table above.

print(Sys.time() - start_time) 

# In total, the script needs about 2-3h to run.
