---
title: "Other countries"
author: "Cornelius Erfort"
date: "18 Aug 2021"
output: 
  pdf_document:
    dev: cairo_pdf
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, tidy.opts=list(width.cutoff = 80), tidy = T, python.reticulate = F)
knitr::opts_knit$set(root.dir = dirname(getwd()))

```

# Setting up

This script requires the files which are not included on GitHub.

## Loading packages

This script is based mainly on the functions of the quanteda package. For the cross-validation of the textmodels, quanteda.classifiers has to be loaded from GitHub.

```{r packages, message=FALSE, warning=FALSE, results='hide'}
start_time <- Sys.time()

packages <- c(
  "quanteda", "quanteda.textplots", "quanteda.textmodels", "quanteda.textstats", "quanteda.classifiers", "dplyr", "tm", "rmarkdown", "plyr", "readr", "ggplot2", "stringr", "formatR", "readstata13", "lubridate", "glmnet", "kableExtra", "stargazer", "tidyr", "extrafont", "xlsx", "tools")

lapply(packages[!(packages %in% rownames(installed.packages()))], install.packages)

invisible(lapply(packages, require, character.only = T))

theme_update(text = element_text(family = "LM Roman 10")) # Set font family for ggplot

loadfonts()
loadfonts(device = "pdf")
source("scripts/functions.R")

seed <- 1621447882
set.seed(seed)

if(!dir.exists("other-countries")) dir.create("other-countries")

```


## Load the unlabeled data

```{r unlabeled, out.width = "80%"}
list.files("data/all")

unlabeled <- data.frame()

if(file.exists("other-countries/unlabeled.RData")) load("other-countries/unlabeled.RData") else {
  for (country in list.files("data/all", full.names = T)) {
    print(country)
    load(country)
    unlabeled <- get(basename(country) %>% str_remove("\\.[:alpha:]*")) %>% 
      filter(!is.na(date)) %>% mutate(date = str_replace_all(date, "_", "-"),
                                      htext = str_c(header, " ", text)) %>%
      select(c(country, id, party, year, date, filepath, htext)) %>%
      rbind.fill(unlabeled)
  }
  
  table(unlabeled$country, useNA = "always")
  nrow(unlabeled)
  names(unlabeled)
  
  # Remove ~500 press releases without date
  unlabeled$date %>% ymd() %>% is.na() %>% table
  unlabeled$date <- ymd(unlabeled$date)
  unlabeled <- filter(unlabeled, !is.na(date))
  
  save(unlabeled, file = "other-countries/unlabeled.RData")
}


table(unlabeled$country)

```

## Load the labeled data

```{r labeled, out.width = "80%"}

# Read the labeled data into one dataframe
labeled <- data.frame()

if(file.exists("other-countries/labeled.RData")) load("other-countries/labeled.RData") else {
  for (country in list.files("data/labeled", full.names = T) %>% str_subset("(xlsx)|(csv)")) {
    
    if(file_ext(country) == "xlsx") {
      print("xlsx")
      print(basename(country) %>% str_remove("-.*"))
      labeled <- read.xlsx(country, sheetIndex = 1) %>% 
        mutate(country = basename(country) %>% str_remove("-.*")) %>% 
        rbind.fill(labeled)
      print(nrow(labeled))
    } else {
      print("csv")
      print(basename(country) %>% str_remove("-.*"))
      labeled <- read.csv(country,
                          encoding = ifelse(str_detect(country, "spain"), "latin1", "unknown"),
                          sep = ifelse(str_detect(country, "ireland"), ";", ",")) %>%
        mutate(country = basename(country) %>% str_remove("-.*")) %>% 
        rbind.fill(labeled)
      print(nrow(labeled))
    } 
  }
  
  table(labeled$country, useNA = "always")
  nrow(labeled)
  
  save(labeled, file = "other-countries/labeled.RData")

}

# Add cross-samples from Sweden, Denmark, Poland
for (file in list.files("data/labeled/preview", full.names = T)) {
  print(file)
  preview <- read.xlsx(file, sheetIndex = 1) %>% filter(issue_coder1 != 19) %>% dplyr::mutate(issue = str_replace_all(issue_coder1, c("a" = "1", "b" = "2")) %>% as.numeric, id = as.numeric(id)) %>% select(issue, id, country) %>% filter(!is.na(issue) & issue > 0)
  preview$issue %>% table
  print(unique(preview$issue))
 # labeled <- rbind.fill(labeled, preview)

}
save(labeled, file = "other-countries/labeled.RData")

```


## Prepare data for models

```{r clean-labeled, out.width = "80%"}
# Check issue labels
labeled$issue %>% as.numeric %>% table(useNA = "always")

# Remove missings
labeled <- filter(labeled, !is.na(issue))

# Only keep country, issue and id for merging
labeled <- select(labeled, c(country, id, issue))

str(labeled)

# Merge labels to unlabeled and subset to relevant vars

if(file.exists("other-countries/textpress.RData")) load("other-countries/textpress.RData") else {
  names(unlabeled)
  textpress <- unlabeled %>% select("country", "htext", "party", "date", "id") %>% merge(labeled, by = c("country",   "id"), all.x = T)
  
  str(textpress)
  
  # Make issue numeric
  textpress$issue <- as.numeric(textpress$issue)
  
  # Check issue labels
  textpress$issue %>% table(useNA = "always")
  
  # Combine header and text into one vector
  # textpress$htext <- str_c(textpress$header, " ", textpress$text)
  
  # test <- within(textpress,  htext <- paste0(header, text, sep=" "))
  
  # Make order of documents random
  textpress <- textpress[sample(1:nrow(textpress), nrow(textpress)), ]
  
  # Add folds variable for cross-validation (stratified by country)
  textpress$cv_sample <- NA
  for (country in unique(textpress$country)) textpress$cv_sample[textpress$country == country] <- sample(1:5,   nrow(textpress[textpress$country == country, ]), replace = T)
  
  
  save(textpress, file = "other-countries/textpress.RData")
  
}



```


# Ridge (L2)

```{r tm-ridge}

# Only keep labeled
corp_press <- filter(textpress, !is.na(issue))

corp_press <- corpus(corp_press$htext,
                       docvars = select(corp_press, c(country, issue, party, cv_sample)))

ridge_eval <- data.frame()

for (country in unique(corp_press$country)) {
  print(country)
  
  corp_country <- corp_press[corp_press$country == country, ]

  # Create alternative dfm (bigrams and tfidf)
  dfmat_alt <- corpus_subset(corp_country) %>%
    tokens() %>% tokens_ngrams(n = 1:2) %>%
    dfm(remove = stopwords(str_replace_all(country, c("germany" = "de", "austria" = "de", "spain" = "es", "netherlands" = "nl", "ireland" = "en", "denmark" = "da", "sweden" = "sv", "poland" = "de"))), # Stem and remove stopwords, punctuation etc.
        remove_punct = T, remove_number = T, remove_symbols = T, remove_url =   T) %>% dfm_wordstem(language = str_replace_all(country, c("germany" = "de", "austria" = "de", "spain" = "es", "netherlands" = "nl", "ireland" = "en", "denmark" = "da", "sweden" = "sv", "poland" = "de"))) %>%
    dfm_trim(max_docfreq = .06, # Remove words occurring >6% of docs
             docfreq_ = "prop") %>%
     dfm_trim(min_docfreq = 5, # Remove words occurring in <5 docs
             docfreq_ = "count") %>%
    suppressWarnings()
  
  ridge_eval <- textmodel_evaluate(dfmat_alt, dfmat_alt$issue, k = 5, model = "textmodel_svm", fun = "accuracy", seed = seed, parameters = list(type = 7)) %>% dplyr::mutate(country = country) %>% rbind.fill(ridge_eval)
  print(aggregate(cbind(time, accuracy) ~ country + seed, ridge_eval, mean)$accuracy)
}

aggregate(cbind(time, accuracy) ~ country + seed, ridge_eval, mean) %>% View



```

# Transformers

BETO, Multi-lingual.

```{r transfer}
names(textpress)

# Show distribution of text length
sapply(textpress$htext, str_length) %>% density() %>% plot

# Count words/tokens
sapply(textpress$htext, function(x) lengths(gregexpr("\\W+", x)) + 1) %>% max # max_seq_length = 512

# Add labels 0-16 (instead of CAP labels)
labels <- data.frame(issue = unique(textpress$issue) %>% sort, label = c(0:22))
textpress <- merge(textpress, labels, by = "issue", all.x = T)

textpress$label[is.na(textpress$issue)] <- -1

# Write to csv
select(textpress, c(htext, label, cv_sample, country, id)) %>% write.csv("other-countries/alldocs.csv", row.names = F)

```