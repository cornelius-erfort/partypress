---
title: "Other countries"
author: "Cornelius Erfort"
date: "18 Aug 2021"
output: 
  pdf_document:
    dev: cairo_pdf
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, tidy.opts=list(width.cutoff = 80), tidy = T, python.reticulate = F)
knitr::opts_knit$set(root.dir = dirname(getwd()))

```

# Setting up

This script requires the files which are not included on GitHub.

## Loading packages

This script is based mainly on the functions of the quanteda package. For the cross-validation of the textmodels, quanteda.classifiers has to be loaded from GitHub.

```{r packages, message=FALSE, warning=FALSE, results='hide'}
start_time <- Sys.time()

packages <- c(
  "quanteda", "quanteda.textplots", "quanteda.textmodels", "quanteda.textstats", "quanteda.classifiers", "dplyr", "tm", "rmarkdown", "plyr", "readr", "ggplot2", "stringr", "formatR", "readstata13", "lubridate", "glmnet", "kableExtra", "stargazer", "tidyr", "extrafont", "xlsx", "tools")

lapply(packages[!(packages %in% rownames(installed.packages()))], install.packages)

invisible(lapply(packages, require, character.only = T))

theme_update(text = element_text(family = "LM Roman 10")) # Set font family for ggplot

loadfonts()
loadfonts(device = "pdf")
source("scripts/functions.R")

seed <- 1621447882
set.seed(seed)

if(!dir.exists("other-countries")) dir.create("other-countries")

```


## Loading data

```{r data, out.width = "80%"}
# Read the labeled data into one dataframe
labeled <- data.frame()

labeled <- read.dta13("data/labeled/netherlands-labeled.dta") %>% rbind.fill
nrow(labeled)

if(file.exists("other-countries/labeled.RData")) load("other-countries/labeled.RData") else {
  for (country in list.files("data/labeled", full.names = T) %>% str_subset("(xlsx)|(csv)")) {
    
    if(file_ext(country) == "xlsx") {
      print("xlsx")
      print(country)
      labeled <- read.xlsx(country, sheetIndex = 1) %>% 
        mutate(country = basename(country) %>% str_remove("-.*")) %>% 
        rbind.fill(labeled)
      print(nrow(labeled))
    } else {
      print("csv")
      print(country)
      labeled <- read.csv(country,
                          encoding = ifelse(str_detect(country, "spain"), "latin1", "unknown"),
                          sep = ifelse(str_detect(country, "ireland"), ";", ",")) %>%
        mutate(country = basename(country) %>% str_remove("-.*")) %>% 
        rbind.fill(labeled)
      print(nrow(labeled))
    } 
  }
  
  table(labeled$country, useNA = "always")
  nrow(labeled)
  
  names(labeled)
  
  labeled <- filter(labeled, !is.na(date))

  
  # Tidy date
  labeled$date[substr(labeled$date, 5, 5) == "-"] <- labeled$date[substr(labeled$date,   5, 5) == "-"] %>% ymd()
  labeled$date[substr(labeled$date, 3, 3) %in% c("-", "/")] <-   labeled$date[substr(labeled$date, 3, 3) %in% c("-", "/")] %>% dmy()
  labeled$date <- labeled$date %>% as.numeric() %>% as.Date(origin = "1970-01-01")
  nrow(labeled)
  
  labeled <- filter(labeled, !is.na(date))

  
  # Tidy issue
  # labeled$issue[is.na(labeled$issue)] <- labeled$Issue[is.na(labeled$issue)]
  # labeled$issue[is.na(labeled$issue)] <-   labeled$X1st.coding..issue[is.na(labeled$issue)]
  labeled$issue <- str_replace_all(labeled$issue, c("19a" = "191", "19b" =  "192"))
  
  labeled$issue %>% unique %>% sort
  labeled$issue %>% unique %>% sort %>% length
  filter(labeled, country == "germany")$issue %>% unique %>% sort %>% length

  table(labeled$issue, useNA = "always")
  labeled <- filter(labeled, !is.na(issue) & issue != ".") # netherlands and ireland   are not yet labeled
  
  save(labeled, file = "other-countries/labeled.RData")
}


table(labeled$country, useNA = "always")

# Subset to relevant vars
textpress <- labeled %>% select("country", "header", "text", "issue", "party", "date", "id")
rm(labeled)

# Remove non-thematic press releases
# textpress <- textpress %>% filter(issue != 98)
nrow(textpress)
textpress <- filter(textpress, !(header %>% tolower() %>% str_detect("einladung zum presse")))
nrow(textpress)

```

## Prepare data


```{r categories}
textpress$issue <- as.numeric(textpress$issue)

textpress$htext <- str_c(textpress$header, " ", textpress$text)

# Make order of documents random
textpress <- textpress[sample(1:nrow(textpress), nrow(textpress)), ]

# Add folds variable for cross-validation (stratified by country)
textpress$cv_sample <- NA
for (country in unique(textpress$country)) textpress$cv_sample[textpress$country == country] <- sample(1:5, nrow(textpress[textpress$country == country, ]), replace = T)


if(!file.exists("other-countries/textpress.RData")) save(textpress, file = "other-countries/textpress.RData")


```


# Ridge (L2)

```{r tm-ridge}

corp_press <- corpus(str_c(textpress$header, " ", textpress$text),
                       docvars = select(textpress, c(country, issue, party, cv_sample)))

ridge_eval <- data.frame()

for (country in unique(corp_press$country)) {
  print(country)
  
  corp_country <- corp_press[corp_press$country == country, ]

  # Create alternative dfm (bigrams and tfidf)
  dfmat_alt <- corpus_subset(corp_country) %>%
    tokens() %>% tokens_ngrams(n = 1:2) %>%
    dfm(remove = stopwords(str_replace_all(country, c("germany" = "de", "austria" = "de", "spain" = "es", "netherlands" = "nl"))), # Stem and remove stopwords, punctuation etc.
        remove_punct = T, remove_number = T, remove_symbols = T, remove_url =   T) %>% dfm_wordstem(language = str_replace_all(country, c("germany" = "de", "austria" = "de", "spain" = "es", "netherlands" = "nl"))) %>%
    dfm_trim(max_docfreq = .06, # Remove words occurring >6% of docs
             docfreq_ = "prop") %>%
     dfm_trim(min_docfreq = 5, # Remove words occurring in <5 docs
             docfreq_ = "count") %>%
    suppressWarnings()
  
  ridge_eval <- textmodel_evaluate(dfmat_alt, dfmat_alt$issue, k = 5, model = "textmodel_svm", fun = "accuracy", seed = seed, parameters = list(type = 7)) %>% dplyr::mutate(country = country) %>% rbind.fill(ridge_eval)
  
}

aggregate(cbind(time, accuracy) ~ country + seed, ridge_eval, mean) %>% View



```

# Transformers

BETO, Multi-lingual.

```{r transfer}
names(textpress)

# Show distribution of text length
sapply(textpress$htext, str_length) %>% density() %>% plot

# Count words/tokens
sapply(textpress$htext, function(x) lengths(gregexpr("\\W+", x)) + 1) %>% max # max_seq_length = 512

# Add labels 0-16 (instead of CAP labels)
labels <- data.frame(issue = unique(textpress$issue) %>% sort, label = c(0:22))
textpress <- merge(textpress, labels, by = "issue")

# Write to csv
select(textpress, c(htext, label, cv_sample, country, id)) %>% write.csv("other-countries/alldocs.csv", row.names = F)

```