---
title: "Other countries"
author: "Cornelius Erfort"
date: "18 Aug 2021"
output: 
  pdf_document:
    dev: cairo_pdf
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, tidy.opts=list(width.cutoff = 80), tidy = T, python.reticulate = F)
knitr::opts_knit$set(root.dir = dirname(getwd()))

```

# Setting up

This script requires the files which are not included on GitHub.

## Loading packages

This script is based mainly on the functions of the quanteda package. For the cross-validation of the textmodels, quanteda.classifiers has to be loaded from GitHub.

```{r packages, message=FALSE, warning=FALSE, results='hide'}
start_time <- Sys.time()

packages <- c(
  "quanteda", "quanteda.textplots", "quanteda.textmodels", "quanteda.textstats", "dplyr", "tm", "rmarkdown", "plyr", "readr", "ggplot2", "stringr", "formatR", "readstata13", "lubridate", "glmnet", "kableExtra", "stargazer", "tidyr", "extrafont", "xlsx", "tools")

lapply(packages[!(packages %in% rownames(installed.packages()))], install.packages)

invisible(lapply(packages, require, character.only = T))

theme_update(text = element_text(family = "LM Roman 10")) # Set font family for ggplot

loadfonts()
loadfonts(device = "pdf")
source("scripts/functions.R")

seed <- 1621447882
set.seed(seed)

```


## Loading data

```{r data, out.width = "80%"}
# Read the labeled data into one dataframe

if(file.exists("other-countries/labeled.RData")) load("other-countries/labeled.RData") else {
  labeled <- data.frame()
  for (country in list.files("data/labeled", full.names = T)) {
    
    if(file_ext(country) == "xlsx") {
      print("xlsx")
      print(country)
      labeled <- read.xlsx(country, sheetIndex = 1) %>% 
        mutate(country = basename(country) %>% str_remove("-.*")) %>% 
        rbind.fill(labeled)
      print(nrow(labeled))
    } else {
      print("csv")
      print(country)
      labeled <- read.csv(country,
                          encoding = ifelse(str_detect(country, "spain"), "latin1", "unknown"),
                          sep = ifelse(str_detect(country, "ireland"), ";", ",")) %>%
        mutate(country = basename(country) %>% str_remove("-.*")) %>% 
        rbind.fill(labeled)
      print(nrow(labeled))
    } 
  }
  
  table(labeled$country, useNA = "always")
  nrow(labeled)
  
  names(labeled)
  
  # Tidy date
  labeled$date[substr(labeled$date, 5, 5) == "-"] <- labeled$date[substr(labeled$date,   5, 5) == "-"] %>% ymd()
  labeled$date[substr(labeled$date, 3, 3) %in% c("-", "/")] <-   labeled$date[substr(labeled$date, 3, 3) %in% c("-", "/")] %>% dmy()
  labeled$date <- labeled$date %>% as.numeric() %>% as.Date(origin = "1970-01-01")
  labeled <- filter(labeled, !is.na(date))
  nrow(labeled)
  
  # Tidy issue
  # labeled$issue[is.na(labeled$issue)] <- labeled$Issue[is.na(labeled$issue)]
  # labeled$issue[is.na(labeled$issue)] <-   labeled$X1st.coding..issue[is.na(labeled$issue)]
  labeled$issue <- str_replace_all(labeled$issue, c("19a" = "191", "19b" =  "192"))
  
  table(labeled$issue, useNA = "always")
  labeled <- filter(labeled, !is.na(issue) & issue != ".") # netherlands and ireland   are not yet labeled
  
  save(labeled, file = "other-countries/labeled.RData")
}


table(labeled$country, useNA = "always")

# Subset to relevant vars
textpress <- labeled %>% select("country", "header", "text", "issue", "party", "date", "id")
rm(labeled)

# Remove non-thematic press releases
textpress <- textpress %>% filter(issue != 98)
nrow(textpress)
textpress <- filter(textpress, !(header %>% tolower() %>% str_detect("einladung zum presse")))
nrow(textpress)

```

## Merging categories

In order to improve the classification, similar topics are merged or subsumed under the "Other" category. In practice, press releases regarding, for instance, Environment and Energy are often not distinguishable. Furthermore, small categories with very few observations are not suitable for automated classification.

```{r categories}
textpress$issue_r1 <- as.numeric(textpress$issue)

# Merge categories
textpress <- textpress %>% mutate(issue_r1 = recode(issue_r1,
                           `8`  = 7,  # Environment & Energy
                           `13` = 10, # Transportation & Welfare
                           `14` = 10, # Housing & Welfare
                           `18` = 15, # Foreign Trade and Domestic Commerce
                           `98` = 99, # Non-thematic
                           `23` = 99) # Culture: Too few observations
                                                  )
textpress$htext <- str_c(textpress$header, " ", textpress$text)

# Make order of documents random
textpress <- textpress[sample(1:nrow(textpress), nrow(textpress)), ]

# Add folds variable for cross-validation (stratified by country)
textpress$cv_sample <- NA
for (country in unique(textpress$country)) textpress$cv_sample[textpress$country == country] <- sample(1:5, nrow(textpress[textpress$country == country, ]), replace = T)


if(!file.exists("other-countries/textpress.RData")) save(textpress, file = "other-countries/textpress.RData")


```


# Ridge (L2)

```{r tm-ridge}

corp_press <- corpus(str_c(textpress$header, " ", textpress$text),
                       docvars = select(textpress, c(country, issue_r1, party, cv_sample)))

ridge_eval <- data.frame()

for (country in unique(corp_press$country)) {
  print(country)
  
  corp_country <- corp_press[corp_press$country == country, ]

  # Create alternative dfm (bigrams and tfidf)
  dfmat_alt <- corpus_subset(corp_country) %>%
    tokens() %>% tokens_ngrams(n = 1:2) %>%
    dfm(remove = stopwords(ifelse(country != "spain", "de", "es")), # Stem and remove stopwords, punctuation etc.
        stem = T, remove_punct = T, remove_number = T, remove_symbols = T, remove_url =   T) %>%
    dfm_trim(max_docfreq = .06, # Remove words occurring >6% of docs
             docfreq_ = "prop") %>%
     dfm_trim(min_docfreq = 5, # Remove words occurring in <5 docs
             docfreq_ = "count") %>%
    suppressWarnings()
  
  ridge_eval <- textmodel_evaluate(dfmat_alt, dfmat_alt$issue_r1, k = 5, model = "textmodel_svm", fun = "accuracy", seed = seed, parameters = list(type = 7)) %>% dplyr::mutate(country = country) %>% rbind.fill(ridge_eval)
  
}

aggregate(cbind(time, accuracy) ~ country + seed, ridge_eval, mean) %>% View



```

# Transformers

BETO, Multi-lingual.

```{r transfer}
names(textpress)

# Show distribution of text length
sapply(textpress$htext, str_length) %>% density() %>% plot

# Count words/tokens
sapply(textpress$htext, function(x) lengths(gregexpr("\\W+", x)) + 1) %>% max # max_seq_length = 512

# Add labels 0-16 (instead of CAP labels)
labels <- data.frame(issue_r1 = unique(textpress$issue_r1) %>% sort, label = c(0:16))
textpress <- merge(textpress, labels, by = "issue_r1")

# Write to csv
select(textpress, c(htext, label, cv_sample, country, id)) %>% write.csv("other-countries/alldocs.csv", row.names = F)

```