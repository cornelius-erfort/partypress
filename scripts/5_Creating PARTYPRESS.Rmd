---
title: "Creating PARTYPRESS"
author: "Cornelius Erfort"
date: "8/5/2021"
output: 
  pdf_document:
    dev: cairo_pdf
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, tidy.opts=list(width.cutoff = 80), tidy = T, python.reticulate = F)
knitr::opts_knit$set(root.dir = dirname(getwd()))
```

# Summary

We create the complete PARTYPRESS dataset. Additionally, we create datasets with data aggregated over time (monthly and weekly).


# Setting up

This script requires the files which are not included on GitHub.

## Loading packages

```{r packages, message=FALSE, warning=FALSE, results='hide'}
start_time <- Sys.time()

packages <- c(
  "quanteda", "quanteda.textmodels", "dplyr", "caret", "randomForest", "tm", "rmarkdown", "plyr", "readr", "ggplot2", "stringr", "formatR", "readstata13", "lubridate", "reticulate", "doMC", "glmnet", "kableExtra", "stargazer", "extrafont", "ggrepel", "haven", "tidyr")


lapply(packages[!(packages %in% rownames(installed.packages()))], install.packages)

if(!("quanteda.classifiers" %in% rownames(installed.packages()))) {
  remotes::install_github("quanteda/quanteda.classifiers")
} 

invisible(lapply(c(packages, "quanteda.classifiers"), require, character.only = T))

loadfonts()
loadfonts(device = "pdf")
theme_update(text = element_text(family = "LM Roman 10")) # Set font family for ggplot

source("scripts/functions.R")

load("files/press.RData")


```

# Classification of unlabeled data

## Using the fine-tuned Transformers

We trained the models using a set of more than 27,000 labeled documents, around 1500-2500  per country. In order to obtain aggregated measures of issue attention, we predict the issue categories of all labeled and unlabeled press releases in our sample.


```{r unlabeled}
# Multilingual
# Load the predicted labels
multi_pred_all <- read_csv("files/multilingual-all_predictions.csv", col_names = F)
multi_pred_all <- unique(multi_pred_all)
names(multi_pred_all) <- c("country", "label", "id")
multi_pred_all <- merge(multi_pred_all, data.frame(multi = unique(press$issue) %>% sort, label = (1:length(unique(press$issue) %>% sort) - 1)), by = "label", all.x = T) %>% select(-c(label))

# multi_pred_all <- dplyr::rename(multi_pred_all, issue_multi = multi)
# test <- merge(partypress, multi_pred_all, by.x = c("country_name", "id"), by.y = c("country", "id"), all.x = T)

partypress <- merge(press, multi_pred_all, by = c("country", "id"), all.x = T)

partypress <- partypress %>% select(-c(party, party.y)) %>% dplyr::rename(party = party_name)

# Monolingual
mono_pred_all <- read_csv("files/monolingual-all_predictions.csv", col_names = F)
mono_pred_all <- unique(mono_pred_all)
names(mono_pred_all) <- c("country", "label", "id")
mono_pred_all <- merge(mono_pred_all, data.frame(mono = unique(press$issue) %>% sort, label = (1:length(unique(press$issue) %>% sort) - 1)), by = "label", all.x = T) %>% select(-c(label))


partypress <- merge(partypress, mono_pred_all, by = c("country", "id"), all.x = T)

names(partypress)
partypress <- partypress %>% select(-c(country.y)) 


table(partypress$mono == partypress$multi)/nrow(partypress)

```
# Add parlgov data

```{r}
parties <- read.csv("data/parlgov_view_party.csv", encoding = "UTF-8") %>% select(c(party_name_english, party_name, family_name, party_id)) %>% dplyr::rename(parlgov_id = party_id)

partypress <- merge(partypress, parties, by = "parlgov_id", all.x = T)
```



# Adding labels based on country-specific Ridge models

```{r ridge-predict}
presscorpus <- corpus(str_c(partypress$header, " ", partypress$text),
                       docvars = select(partypress, c(country, id, issue, party_name, cv_sample)))

if(!file.exists("files/ridge_pred_all.RData")) {
  ridge_pred_all <- data.frame()
for (country in partypress$country %>% unique) {
  print(country)
  
  # if(country %in% unique(ridge_pred_all$country)) next
  
  countrycorpus <-  presscorpus[presscorpus$country == country, ]
  ndoc(countrycorpus) %>% print
  
  # Stopwords
  if(country == "poland") countrystop <-  stopwords::stopwords("pl", source = "stopwords-iso") else countrystop <- stopwords(str_replace_all(country, c("germany" = "de", "austria" = "de", "spain" = "es", "netherlands" = "nl", "ireland" = "en", "uk" = "en", "sweden" = "sw", "denmark" = "da")))
  countrystop
  
  # Create alternative dfm (bigrams and tfidf)
  dfmat_alt <- countrycorpus[countrycorpus$cv_sample != -1, ] %>%
    tokens() %>% tokens_ngrams(n = 1:2) %>%
    dfm(remove = countrystop, # Stem and remove stopwords, punctuation etc.
        stem = T, remove_punct = T, remove_number = T, remove_symbols = T, remove_url = T) %>% 
    dfm_trim(max_docfreq = .06, # Remove words occurring >6% of docs
             docfreq_ = "prop") %>%
    dfm_trim(min_docfreq = 5, # Remove words occurring in <5 docs
             docfreq_ = "count") %>% suppressWarnings()
  
  dfm_all <- countrycorpus %>%
    tokens() %>% tokens_ngrams(n = 1:2) %>%
    dfm(remove = countrystop, # Stem and remove stopwords, punctuation etc.
        stem = T, remove_punct = T, remove_number = T, remove_symbols = T, remove_url = T) %>% 
    dfm_match(dfmat_alt@Dimnames$features) # Match features of the training data
    ridge_pred_all <- data.frame(country = country,
                             id = dfm_all$id,
                             prediction = textmodel_svm(dfm_subset(dfm_all, dfm_all$cv_sample != -1), dfm_subset(dfm_all, dfm_all$cv_sample != -1)$issue, type = 7) %>%
        predict(., newdata = dfm_all)) %>% rbind.fill(ridge_pred_all)
    save(ridge_pred_all, file = "files/ridge_pred_all.RData")
} 
} else load("files/ridge_pred_all.RData")

ridge_pred_all <- ridge_pred_all %>% dplyr::rename(ridge = prediction)
ridge_pred_all <- unique(ridge_pred_all)
# select(ridge_pred_all)

# ridge_pred_all <- dplyr::rename(ridge_pred_all, ridge = prediction)
partypress <- merge(partypress, ridge_pred_all, by = c("country", "id"), all.x = T)


## Add SuperLearner
# Load the predicted labels
super_pred_all <- read_csv("files/superlearner-all_predictions.csv", col_names = F)
super_pred_all <- unique(super_pred_all)
names(super_pred_all) <- c("country", "prediction", "label", "id")
super_pred_all <- merge(super_pred_all, data.frame(super = unique(press$issue) %>% sort, label = (1:length(unique(press$issue) %>% sort) - 1)), by.y = "label", by.x = "prediction", all.x = T) %>% select(-c(label, prediction))

super_pred_all$super %>% table

partypress <- merge(partypress, super_pred_all, by = c("country", "id"), all.x = T)

partypress$party_name %>% table


table(partypress$issue_ridge == partypress$issue_multi)/nrow(partypress)
table(partypress$issue_super == partypress$issue_multi)/nrow(partypress)



partypress$month <- as.character(partypress$date) %>% substr(3, 8) %>% str_remove_all("-")

partypress$month %>% unique %>% length

partypress$month_start <- floor_date(partypress$date, "month")
partypress$month_end <- ceiling_date(partypress$date, "month") - 1
partypress$month_start %>% unique %>% length

partypress$calendar_week <- week(partypress$date)

partypress$week_start <- floor_date(partypress$date, "weeks", week_start = 1)
partypress$week_end <- ceiling_date(partypress$date - 1, "weeks", week_start = 7)


partypress <- select(partypress, c("country", "id", "parlgov_id", "party", "party_name", "party_name_english", "family_name", "date", "month", "month_start", "month_end", "calendar_week", "week_start", "week_end", "header", "multi", "mono", "ridge", "super", "issue", "issue_cross", "position", "position_cross", "cv_sample", "text")) %>% 
  dplyr::rename(c(country_name = country,
                  issue_multi = multi,
                  issue_mono = mono,
                  issue_ridge = ridge,
                  issue_super = super,
                  issue = issue,
                  issue_coder2 = issue_cross,
                  position = position,
                  position_coder2 = position_cross)) %>% 
  mutate(issue_multi = issue_multi %>% as.numeric(),
                  issue_mono = issue_mono %>% as.numeric(),
                  issue_ridge = issue_ridge %>% as.character %>% as.numeric(),
                  issue_super = issue_super %>% as.numeric(),
                  issue = issue %>% as.numeric(),
                  issue_coder2 = issue_coder2 %>% as.numeric(),
                  position = position %>% as.numeric(),
                  position_coder2 = position_coder2 %>% as.numeric())

partypress_texts <- select(partypress, c("country_name", "id", "text"))

# Main dataset:
# country_name
# id (unique within country_name)
# parlgov_id
# 
# party - party abbreviation (parlgov)
# party_name - party name (parlgov)
# party_name_english - party name in English (parlgov)
# family_name - party family name (parlgov)
# date (format YYYY-MM-DD)
# month (format YYYY-MM)
# month_start
# month_end
# calendar_week (Calendar week: values 1-53)
# week_start (date of previous Monday, format YYYY-MM-DD)
# week_end (date of following Sunday, format YYYY-MM-DD)
# header
# issue_multi (issue category predicted from multilingual BERT using all labeled docs from all countries)
# issue_mono (issue category predicted from monolingugal BERT using only labeled docs from one country)
# issue_ridge (issue category predicted from Ridge models, separate models by country)
# issue_super (issue category predicted from SuperLearner models, separate models by country)
# issue_coder (issue category hand coded by 1st OR 2nd country expert coder)
# issue_coder2  (issue category hand coded by 2nd country expert coder, only for texts coded by both coders)

# Additional vars
# position_coder (position hand coded by 1st OR 2nd country expert coder)
# position_coder2  (position category hand coded by 2nd country expert coder, only for texts coded by both coders)
# cv_sample (used in cross validation of evaluation models, k = 1,2,3,4,5, not used: -1)




# partypress <- select(partypress, -c(text))

partypress <- select(partypress, c(country_name, id, parlgov_id, party, party_name, party_name_english, family_name, date, month, month_start, month_end, calendar_week, week_start, week_end,  header, issue_multi, issue_mono, issue_ridge, issue_super, issue, issue_coder2, position, position_coder2, cv_sample))

partypress <- partypress[order(partypress$country_name, partypress$parlgov_id, partypress$date), ]

saveRDS(partypress, file =  "publication/rds/partypress.RDS")
# partypress <- readRDS("publication/rds/partypress.RDS")
write.csv(partypress, file = "publication/csv/partypress.csv", row.names = F, fileEncoding = "UTF-8")
write_dta(partypress, path = "publication/dta/partypress.dta")

# Issue category names for merging. Merge via issue_*
# issue
# issue_name
partypress_issues <- 
  data.frame(issue = c(1:10, 12:18, 191:192, 20, 23, 98, 99), 
             issue_name = c("Macroeconomics", "Civil Rights", "Health", "Agriculture", "Labor", "Education", 
              "Environment", "Energy", "Immigration", "Transportation", "Law and Crime", 
              "Social Welfare", "Housing", "Domestic Commerce", "Defense", "Technology", 
              "Foreign Trade", "International Affairs", "European Integration", "Government Operations", "Culture", "Non-thematic", "Other"))

saveRDS(partypress_issues, file = "publication/rds/partypress_issues.RDS")
# partypress_issues <- readRDS("publication/rds/partypress_issues.RDS")
write.csv(partypress_issues, file = "publication/csv/partypress_issues.csv", row.names = F, fileEncoding = "UTF-8")
write_dta(partypress_issues, path = "publication/dta/partypress_issues.dta")

# Texts separate because they use a lot of space but some users may not be interested in raw text. Merge via country_name + id
# country_name
# id (unique within country_name)
# text


saveRDS(partypress_texts, file = "publication/rds/partypress_texts.RDS")
write.csv(partypress_texts, file = "publication/csv/partypress_texts.csv", row.names = F, fileEncoding = "UTF-8")
# write_dta(partypress_texts, path = "publication/partypress_texts.dta") ## too large


# partypress_issues <- readRDS("publication/partypress_issues.RDS")
```

## Aggregation of the issues categories over time and party

To measure parties' evolving issue agendas, we aggregate the category counts over time.


### Monthly

```{r monthly}

# Create dataframe with only necessary vars
monthly_agendas <- partypress %>% select(c(country_name, parlgov_id, party, party_name, party_name_english, family_name, month_start, month_end, issue_multi, issue_mono, issue_ridge, issue_super))

# Reformat long
monthly_agendas <- pivot_longer(monthly_agendas, starts_with("issue_"), names_to = "model", names_prefix = "issue_", values_to = "issue")

# Add variable for counting
monthly_agendas$freq <- 1

# Aggregate by party, date and issue
monthly_agendas <- aggregate(freq ~ country_name + parlgov_id + party + party_name + party_name_english + family_name + month_start + month_end + model + issue, monthly_agendas, sum)

expand_agendas <- expand.grid(parlgov_id = unique(monthly_agendas$parlgov_id), month_start = as.Date(unique(monthly_agendas$month_start), origin = "1970-01-01"), issue = unique(monthly_agendas$issue),  model = unique(monthly_agendas$model))

monthly_agendas <- merge(monthly_agendas, expand_agendas, by = c("parlgov_id", "month_start", "issue", "model"), all = T)
monthly_agendas <- monthly_agendas %>% dplyr::group_by(parlgov_id, month_start) %>% dplyr::mutate(party_sum = sum(freq, na.rm = T)/length(unique(monthly_agendas$model))) %>% filter(party_sum > 0) 

monthly_agendas$party_sum %>% table

# Add var for total press releases per party and month
monthly_agendas$freq[is.na(monthly_agendas$freq)] <- 0
monthly_agendas$share <- monthly_agendas$freq / monthly_agendas$party_sum

summary(monthly_agendas$share)
hist(monthly_agendas$share)

monthly_agendas$issue <- monthly_agendas$issue %>% as.numeric()

monthly_agendas$issue %>% table

# Add issue descriptions
monthly_agendas <- merge(monthly_agendas, partypress_issues, by = "issue") %>% select(-c(freq))

# Fill vars

monthly_agendas <- monthly_agendas %>% dplyr::group_by(parlgov_id) %>% do(fill(., country_name, party, party_name, party_name_english, family_name, .direction = "downup"))
is.na(monthly_agendas$country_name) %>% table
# monthly_agendas %>% filter(parlgov_id == 664) %>% View

monthly_agendas$party_name %>% table

monthly_agendas$month_end <- ceiling_date(monthly_agendas$month_start, "month") - 1

monthly_agendas$month_start <- monthly_agendas$month_start %>% as.Date(origin = "1970-01-01")

monthly_agendas$month <- monthly_agendas$month_start %>% substr(1,7) %>% str_remove("-")

monthly_agendas <- select(monthly_agendas, c(country_name, parlgov_id, party, party_name, party_name_english, family_name, month, month_start, month_end, issue, model, issue_name, share, party_sum))

# Reformat wide
monthly_agendas <- pivot_wider(monthly_agendas, names_from = "model", names_prefix = "share_", values_from = "share")

# monthly_agendas <- as.data.frame(monthly_agendas)



monthly_agendas <- monthly_agendas[order(monthly_agendas$country_name, monthly_agendas$parlgov_id, monthly_agendas$month_start, monthly_agendas$issue), ]

monthly_agendas <- as.data.frame(monthly_agendas)

saveRDS(monthly_agendas, file = "publication/rds/monthly_agendas.RDS")
write.csv(monthly_agendas, "publication/csv/monthly_agendas.csv", row.names = F, fileEncoding = "UTF-8")
write_dta(monthly_agendas, path = "publication/dta/monthly_agendas.dta")

corrgram(select(monthly_agendas, starts_with("share")), upper.panel = panel.cor)


```


### Weekly
```{r weekly}

# Create dataframe with only necessary vars
weekly_agendas <- partypress %>% select(c(country_name, parlgov_id, party, party_name, party_name_english, family_name, week_start, week_end, issue_multi, issue_mono, issue_ridge, issue_super))

# Reformat long
weekly_agendas <- pivot_longer(weekly_agendas, starts_with("issue_"), names_to = "model", names_prefix = "issue_", values_to = "issue")

# Add variable for counting
weekly_agendas$freq <- 1

# Aggregate by party, date and issue
weekly_agendas <- aggregate(freq ~ country_name + parlgov_id + party + party_name + party_name_english + family_name + week_start + week_end + issue + model, weekly_agendas, sum)

expand_agendas <- expand.grid(parlgov_id = unique(weekly_agendas$parlgov_id), week_start = as.Date(unique(weekly_agendas$week_start), origin = "1970-01-01"), issue = unique(weekly_agendas$issue), model = unique(weekly_agendas$model))

weekly_agendas <- merge(weekly_agendas, expand_agendas, by = c("parlgov_id", "week_start", "issue", "model"), all = T)

weekly_agendas <- weekly_agendas %>% dplyr::group_by(parlgov_id, week_start) %>% dplyr::mutate(party_sum = sum(freq, na.rm = T)/length(unique(weekly_agendas$model))) %>% filter(party_sum > 0) 

# weekly_agendas[duplicated(select(weekly_agendas, c(parlgov_id, week_start, issue, model))) | duplicated(select(weekly_agendas, c(parlgov_id, week_start, issue, model)), fromLast = T), ] %>% View
weekly_agendas$party_sum %>% table

# Add var for total press releases per party and month
weekly_agendas$freq[is.na(weekly_agendas$freq)] <- 0
weekly_agendas$share <- weekly_agendas$freq / weekly_agendas$party_sum

summary(weekly_agendas$share)
hist(weekly_agendas$share)

weekly_agendas$issue <- weekly_agendas$issue %>% as.numeric()

# weekly_agendas$issue %>% table

# Add issue descriptions
weekly_agendas <- merge(weekly_agendas, partypress_issues, by = "issue") %>% select(-c(freq))

# Fill vars
weekly_agendas <- weekly_agendas[order(weekly_agendas$country_name, weekly_agendas$parlgov_id, weekly_agendas$week_start, weekly_agendas$issue), ]

weekly_agendas <- weekly_agendas %>% group_by(parlgov_id) %>% tidyr::fill(country_name, party, party_name, party_name_english, family_name)

weekly_agendas$week_end <- ceiling_date(weekly_agendas$week_start, "week")

weekly_agendas$week_start <- weekly_agendas$week_start %>% as.Date(origin = "1970-01-01")

weekly_agendas$calendar_week <- week(weekly_agendas$week_start)


weekly_agendas <- select(weekly_agendas, c(country_name, parlgov_id, party, party_name, party_name_english, family_name, calendar_week, week_start, week_end, issue, model, issue_name, share, party_sum))

weekly_agendas <- unique(weekly_agendas)

# weekly_agendas[select(weekly_agendas, c(parlgov_id, week_start, issue, model)) %>% duplicated, ] %>% View

# Reformat wide
weekly_agendas <- pivot_wider(weekly_agendas, names_from = "model", names_prefix = "share_", values_from = "share")


weekly_agendas <- weekly_agendas[order(weekly_agendas$country_name, weekly_agendas$parlgov_id, weekly_agendas$week_start, weekly_agendas$issue), ]

# weekly_agendas$date <- weekly_agendas$date %>% as.Date(origin = "1970-01-01")

saveRDS(weekly_agendas, file = "publication/rds/weekly_agendas.RDS")
write.csv(weekly_agendas, "publication/csv/weekly_agendas.csv", row.names = F, fileEncoding = "UTF-8")
write_dta(weekly_agendas, path = "publication/dta/weekly_agendas.dta")


corrgram(select(weekly_agendas, starts_with("share")), upper.panel = panel.cor)

```





```{r script_eval}
# Time needed to run script
print(Sys.time() - start_time) 

