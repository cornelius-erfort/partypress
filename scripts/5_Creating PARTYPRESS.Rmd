---
title: "Creating PARTYPRESS"
author: "Cornelius Erfort"
date: "8/5/2021"
output: 
  pdf_document:
    dev: cairo_pdf
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, tidy.opts=list(width.cutoff = 80), tidy = T, python.reticulate = F)
knitr::opts_knit$set(root.dir = dirname(getwd()))
```

# Summary

We create the complete PARTYPRESS dataset. Additionally, we create datasets with data aggregated over time (monthly and weekly).


# Setting up

This script requires the files which are not included on GitHub.

## Loading packages

```{r packages, message=FALSE, warning=FALSE, results='hide'}
start_time <- Sys.time()

packages <- c(
  "quanteda", "quanteda.textmodels", "dplyr", "caret", "randomForest", "tm", "rmarkdown", "plyr", "readr", "ggplot2", "stringr", "formatR", "readstata13", "lubridate", "reticulate", "doMC", "glmnet", "kableExtra", "stargazer", "extrafont", "ggrepel")

lapply(packages[!(packages %in% rownames(installed.packages()))], install.packages)

if(!("quanteda.classifiers" %in% rownames(installed.packages()))) {
  remotes::install_github("quanteda/quanteda.classifiers")
} 

invisible(lapply(c(packages, "quanteda.classifiers"), require, character.only = T))

loadfonts()
loadfonts(device = "pdf")
theme_update(text = element_text(family = "LM Roman 10")) # Set font family for ggplot

source("scripts/functions.R")

load("files/press.RData")


```

# Classification of unlabeled data

## Using the fine-tuned Transformers

We trained the models using a set of more than 27,000 labeled documents, around 1500-2500  per country. In order to obtain aggregated measures of issue attention, we predict the issue categories of all ? labeled and unlabeled press releases in our sample.


```{r unlabeled}

# Load the predicted labels
multi_pred_all <- read_csv("files/multilingual-all_predictions.csv", col_names = F)
multi_pred_all <- unique(multi_pred_all)
names(multi_pred_all) <- c("country", "label", "id")
multi_pred_all <- merge(multi_pred_all, data.frame(multi = unique(press$issue) %>% sort, label = (1:length(unique(press$issue) %>% sort) - 1)), by = "label", all.x = T) %>% select(-c(label))

# multi_pred_all <- dplyr::rename(multi_pred_all, issue_multi = multi)
# test <- merge(partypress, multi_pred_all, by.x = c("country_name", "id"), by.y = c("country", "id"), all.x = T)

partypress <- merge(press, multi_pred_all, by = c("country", "id"), all.x = T)


save(partypress, file = "partypress.RData")


```


# Adding labels based on country-specific Ridge models

```{r ridge-predict}
presscorpus <- corpus(str_c(partypress$header, " ", partypress$text),
                       docvars = select(partypress, c(country, id, issue, party_name, cv_sample)))

if(!file.exists("files/ridge_pred_all.RData")) {
  ridge_pred_all <- data.frame()
for (country in partypress$country %>% unique) {
  print(country)
  
  # if(country %in% unique(ridge_pred_all$country)) next
  
  countrycorpus <-  presscorpus[presscorpus$country == country, ]
  ndoc(countrycorpus) %>% print
  
  # Stopwords
  if(country == "poland") countrystop <-  stopwords::stopwords("pl", source = "stopwords-iso") else countrystop <- stopwords(str_replace_all(country, c("germany" = "de", "austria" = "de", "spain" = "es", "netherlands" = "nl", "ireland" = "en", "uk" = "en", "sweden" = "sw", "denmark" = "da")))
  countrystop
  
  # Create alternative dfm (bigrams and tfidf)
  dfmat_alt <- countrycorpus[countrycorpus$cv_sample != -1, ] %>%
    tokens() %>% tokens_ngrams(n = 1:2) %>%
    dfm(remove = countrystop, # Stem and remove stopwords, punctuation etc.
        stem = T, remove_punct = T, remove_number = T, remove_symbols = T, remove_url = T) %>% 
    dfm_trim(max_docfreq = .06, # Remove words occurring >6% of docs
             docfreq_ = "prop") %>%
    dfm_trim(min_docfreq = 5, # Remove words occurring in <5 docs
             docfreq_ = "count") %>% suppressWarnings()
  
  dfm_all <- countrycorpus %>%
    tokens() %>% tokens_ngrams(n = 1:2) %>%
    dfm(remove = countrystop, # Stem and remove stopwords, punctuation etc.
        stem = T, remove_punct = T, remove_number = T, remove_symbols = T, remove_url = T) %>% 
    dfm_match(dfmat_alt@Dimnames$features) # Match features of the training data
    ridge_pred_all <- data.frame(country = country,
                             id = dfm_all$id,
                             prediction = textmodel_svm(dfm_subset(dfm_all, dfm_all$cv_sample != -1), dfm_subset(dfm_all, dfm_all$cv_sample != -1)$issue, type = 7) %>%
        predict(., newdata = dfm_all)) %>% rbind.fill(ridge_pred_all)
    save(ridge_pred_all, file = "files/ridge_pred_all.RData")
} 
} else load("files/ridge_pred_all.RData")

ridge_pred_all <- ridge_pred_all %>% dplyr::rename(ridge = prediction)
ridge_pred_all <- unique(ridge_pred_all)

# select(ridge_pred_all)

# ridge_pred_all <- dplyr::rename(ridge_pred_all, ridge = prediction)
partypress <- merge(partypress, ridge_pred_all, by = c("country", "id"), all.x = T)

# partypress <- filter(partypress, party_name != "Kukiz'15 (2015-2019)")
partypress$party_name %>% table

partypress$month <- as.character(partypress$date) %>% substr(1, 8) %>% str_c("15") %>% str_replace_all(c("-01-" = "-02-", "-03-" = "-02-", "-04-" = "-05-", "-06-" = "-05-", "-07-" = "-08-", "-09-" = "-08-", "-10-" = "-11-", "-12-" = "-11-")) %>%  ymd()
partypress$month_start <- floor_date(partypress$date, "month")
partypress$month_end <- ceiling_date(partypress$date, "month") - 1


partypress$calendar_week <- week(partypress$date)

partypress$week_start <- floor_date(partypress$date, "weeks", week_start = 1)
partypress$week_end <- ceiling_date(partypress$date, "weeks", week_start = 7)



partypress <- select(partypress, c("country", "id", "parlgov_id", "party_name", "date", "month", "calendar_week", "week_start", "week_end", "header", "multi", "ridge", "issue", "issue_cross", "position", "position_cross", "cv_sample", "text")) %>% 
  dplyr::rename(c(party = party_name,
                  country_name = country,
                  issue_multi = multi,
                  issue_ridge = ridge,
                  issue = issue,
                  issue_coder2 = issue_cross,
                  position = position,
                  position_coder2 = position_cross))

partypress_texts <- select(partypress, c("country_name", "id", "text"))

# Main dataset:
# country_name
# id (unique within country_name)
# parlgov_id
# (other codes?)
# party
# date (format YYYY-MM-DD)
# month (format YYYY-MM)
# month_start
# month_end
# week_start (date of previous Monday, format YYYY-MM-DD)
# week_end (date of following Sunday, format YYYY-MM-DD)
# calendar_week (Calendar week: values 1-53)
# header
# issue_multi (issue category predicted from multilingual BERT using all labeled docs from all countries)
# issue_ridge (issue category predicted from Ridge models, separate models by country)
# issue_coder (issue category hand coded by 1st OR 2nd country expert coder)
# issue_coder2  (issue category hand coded by 2nd country expert coder, only for texts coded by both coders)

# Additional vars
# position_coder (position hand coded by 1st OR 2nd country expert coder)
# position_coder2  (position category hand coded by 2nd country expert coder, only for texts coded by both coders)
# cv_sample (used in cross validation of evaluation models, k = 1,2,3,4,5, not used: -1)
partypress <- select(partypress, -c(text))
save(partypress, file =  "publication/partypress.RData")
write.csv(partypress, file = "publication/partypress.csv")

# Issue category names for merging. Merge via issue_*
# issue
# issue_name
partypress_issues <- 
  data.frame(issue = c(1:10, 12:18, 191:192, 20, 23, 98, 99), 
             issue_name = c("Macroeconomics", "Civil Rights", "Health", "Agriculture", "Labor", "Education", 
              "Environment", "Energy", "Immigration", "Transportation", "Law and Crime", 
              "Social Welfare", "Housing", "Domestic Commerce", "Defense", "Technology", 
              "Foreign Trade", "International Affairs", "European Integration", "Government Operations", "Culture", "Non-thematic", "Other"))

save(partypress_issues, file = "publication/partypress_issues.RData")
write.csv(partypress_issues, file = "publication/partypress_issues.csv")

# Texts separate because they use a lot of space but some users may not be interested in raw text. Merge via country_name + id
# country_name
# id (unique within country_name)
# text


save(partypress_texts, file = "publication/partypress_texts.RData")
write_csv(partypress_texts, file = "publication/partypress_texts.csv")



```

## Aggregation of the issues categories over time and party

To measure parties' evolving issue agendas, we aggregate the category counts over time.


### Monthly

```{r monthly}

# Create dataframe with only necessary vars
monthly_agendas <- partypress %>% select(c(country_name, month_start, issue_multi, party, parlgov_id))

# Add variable for counting
monthly_agendas$freq <- 1

# Aggregate by party, date and issue
monthly_agendas <- aggregate(freq ~ country_name + party + parlgov_id + month_start + issue_multi, monthly_agendas, sum)

# Add observations with zero documents
for (thisparty in unique(monthly_agendas$parlgov_id)) {
  for(thismonth in unique(monthly_agendas$month_start[monthly_agendas$parlgov_id == thisparty])) {
    for(thisissue in unique(monthly_agendas$issue_multi)) {
      if(nrow(monthly_agendas[monthly_agendas$parlgov_id == thisparty & monthly_agendas$month_start == thismonth & monthly_agendas$issue_multi == thisissue, ]) == 0 & nrow(monthly_agendas[monthly_agendas$parlgov_id == thisparty & monthly_agendas$month_start == thismonth, ]) != 0) {
        monthly_agendas <- data.frame(
          parlgov_id = thisparty, month_start = thismonth, issue_multi = thisissue, freq = 0
          ) %>% rbind.fill(monthly_agendas)
}}}}

# Add var for total press releases per party and month
monthly_agendas$party_sum <- ave(monthly_agendas$freq, monthly_agendas$month_start, monthly_agendas$parlgov_id, FUN = sum)

monthly_agendas$attention <- monthly_agendas$freq / monthly_agendas$party_sum

monthly_agendas$issue %>% table

# Add issue descriptions

monthly_agendas <- merge(monthly_agendas, issue_categories, by.x = "issue_multi", by.y = "issue") %>% select(-c(freq))


monthly_agendas <- monthly_agendas %>% group_by(parlgov_id) %>% fill(country_name, party)

# monthly_agendas$date <- monthly_agendas$date %>% as.Date(origin = "1970-01-01")

save(monthly_agendas, file = "publication/monthly_agendas.RData")
write.csv(monthly_agendas, "publication/monthly_agendas.csv")

```


### Weekly
```{r weekly}

# Create dataframe with only necessary vars
weekly_agendas <- partypress %>% select(c(country_name, week_start, issue_multi, party, parlgov_id))

# Add variable for counting
weekly_agendas$freq <- 1

# Aggregate by party, date and issue
weekly_agendas <- aggregate(freq ~ country_name + party + parlgov_id + week_start + issue_multi, weekly_agendas, sum)

# Add observations with zero documents
# for (thisparty in unique(weekly_agendas$parlgov_id)) {
#   for(thisweek in unique(weekly_agendas$week_start[weekly_agendas$parlgov_id == thisparty])) {
#     for(thisissue in unique(weekly_agendas$issue_multi)) {
#       if(nrow(weekly_agendas[weekly_agendas$parlgov_id == thisparty & weekly_agendas$week_start == thisweek & weekly_agendas$issue_multi == thisissue, ]) == 0 & nrow(weekly_agendas[weekly_agendas$parlgov_id == thisparty & weekly_agendas$week_start == thisweek, ]) != 0) {
#         weekly_agendas <- data.frame(
#           parlgov_id = thisparty, week_start = thisweek, issue_multi = thisissue, freq = 0
#           ) %>% rbind.fill(weekly_agendas)
#       }}}}

expand_agendas <- expand.grid(parlgov_id = unique(weekly_agendas$parlgov_id), week_start = as.Date(unique(weekly_agendas$week_start), origin = "1970-01-01"), issue_multi = unique(weekly_agendas$issue_multi))
# test$freq_zero <- 0

weekly_agendas <- merge(weekly_agendas, expand_agendas, by = c("parlgov_id", "week_start", "issue_multi"), all = T)
# weekly_agendas$freq %>% is.na %>% table
weekly_agendas <- weekly_agendas %>% dplyr::group_by(parlgov_id, week_start) %>% dplyr::mutate(party_sum = sum(freq, na.rm = T)) %>% filter(party_sum > 0) 

# Add var for total press releases per party and month
# weekly_agendas$party_sum <- ave(weekly_agendas$freq, weekly_agendas$week_start, weekly_agendas$parlgov_id, FUN = sum)
weekly_agendas$freq[is.na(weekly_agendas$freq)] <- 0
weekly_agendas$attention <- weekly_agendas$freq / weekly_agendas$party_sum

summary(weekly_agendas$attention)
hist(weekly_agendas$attention)

# weekly_agendas$issue_multi %>% table

# Add issue descriptions
weekly_agendas <- weekly_agendas %>% group_by(parlgov_id) %>% fill(country_name, party)

weekly_agendas <- merge(weekly_agendas, issue_categories, by.x = "issue_multi", by.y = "issue") %>% select(-c(freq))

# weekly_agendas$date <- weekly_agendas$date %>% as.Date(origin = "1970-01-01")

save(weekly_agendas, file = "publication/weekly_agendas.RData")
write.csv(weekly_agendas, "publication/weekly_agendas.csv")

```




```{r script_eval}
# Time needed to run script
print(Sys.time() - start_time) 

